{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1cb541",
   "metadata": {},
   "source": [
    "# Fitting <a class=\"label-experiment\" href=\"https://docs.easydiffraction.org/lib/glossary/#experiment-type-labels\">pd-neut-cwl</a> LBCO-HRPT with emcee\n",
    "\n",
    "In this example we take a bayesian approach to the refinment process, and rather than looking for the optimal set of parameters we compute the probability distribution over the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353848c",
   "metadata": {},
   "source": [
    "## Bayesian refinment\n",
    "\n",
    "**Goal:** Finding the posterior probability distribution over parameters, $P(\\boldsymbol{x}|D)$,  given some data D  and prior knowledge.\n",
    "\n",
    "* Experimental data D ($y^\\text{exp}$) \n",
    "* $\\boldsymbol{x}$ parameters to be refined $\\boldsymbol{x}$=($\\boldsymbol{x}_\\text{experiment}$, $\\boldsymbol{x}_\\text{instrument}$, $\\boldsymbol{x}_\\text{sample}$)\n",
    "* Simulated diffraction pattern $y^\\text{sim}=f(\\boldsymbol{x})$\n",
    "\n",
    "\n",
    "The posterior for parameters is\n",
    "\\begin{equation}\n",
    "\\large\n",
    "\\underbrace{P(\\boldsymbol{x}|D)}_\\text{Posterior} = \\underbrace{P(D|\\boldsymbol{x})}_\\text{Likelihood}\\, \\, \\underbrace{P(\\boldsymbol{x})}_\\text{Priors}\n",
    "\\end{equation}\n",
    "\n",
    "### Likelihood\n",
    "We assume independent and (almost)identical normal distributed errors. But we take into account heteroscedasticity that is commonly done for diffraction data, i.e. uncertainty scales with sqrt of intensity, which be achived by modeling the data as\n",
    "\\begin{equation}\n",
    "\\large\n",
    "y^\\text{exp}_i = y^\\text{sim}_i + \\epsilon_i \\\\\n",
    "\\large\n",
    "\\epsilon_i \\sim \\mathcal{N}(\\mu=0, \\sigma^2_i = \\sigma^2 \\cdot y^\\text{exp}_i).\n",
    "\\end{equation}\n",
    "where $\\epsilon_i$ is the error between the experimental (exp) and simulated (sim) diffraction patterns.\n",
    "\n",
    "And then we get a likelihood that looks like\n",
    "\\begin{equation}\n",
    "\\large\n",
    "P(D|\\boldsymbol{x}) \\propto \\exp{\\left (- \\frac{\\sum_i (y^\\text{sim}_i- y^\\text{exp}_i)^2 }{\\sigma^2 y^\\text{exp}_i}\\right )}\n",
    "\\end{equation}\n",
    "Note here that $\\sigma$ is also a free parameter that we need to include in our modeling.\n",
    "\n",
    "\n",
    "### Priors\n",
    "In this example we encode no information in the priors, but in princple any prior knowledge about the same could and should be encoded in the prior probability distribution.\n",
    "\n",
    "\n",
    "### Posterior \n",
    "Finding parameters that maximizes the posterior is equvivalent to regular optimization (least-squares).\n",
    "\n",
    "Obtaining the posterior probability distribution is done via MCMC-sampling with `emcee`, see their [documentation](https://emcee.readthedocs.io/en/stable/) for more details.\n",
    "\n",
    "### More information\n",
    "See the \"Use of Bayesian Inference in Crystallographic Structure Refinement via Full Diffraction Profile Analysis\" (doi: https://doi.org/10.1038/srep31625), for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398ade6d9de3802",
   "metadata": {},
   "source": [
    "## Import EasyDiffraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc490bf498a6200",
   "metadata": {},
   "source": [
    "## Import other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b65bad25e432d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.213013Z",
     "start_time": "2024-11-11T21:04:53.208537Z"
    }
   },
   "outputs": [],
   "source": [
    "import corner  # Library for plotting posterior distributions\n",
    "import emcee  # Library for Markov chain Monte Carlo (MCMC) sampling\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import numpy as np  # Numerical library\n",
    "\n",
    "import easydiffraction as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f605f71",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Here we let `theta` be the parameter vector (including $\\sigma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f28cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.384035Z",
     "start_time": "2024-11-11T21:04:53.381897Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "\n",
    "def compute_rmse(y_target, y_predicted):\n",
    "    \"\"\" Compute root mean squared error (RMSE) between target and predicted values \"\"\"\n",
    "    delta_y = y_target - y_predicted\n",
    "    rmse = np.sqrt(np.mean(delta_y**2))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def compute_mse_weighted(y_target, y_predicted):\n",
    "    \"\"\" Compute the weighted mean squared error. (weighting by y_target) \"\"\"\n",
    "    delta_y = y_target - y_predicted\n",
    "    weight = y_target\n",
    "    mse_weighted = np.mean(delta_y**2 / weight)\n",
    "    return mse_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f4a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.391432Z",
     "start_time": "2024-11-11T21:04:53.387977Z"
    }
   },
   "outputs": [],
   "source": [
    "# theta_0 is close to least-square solution\n",
    "theta_0 = np.array([2.0, 3.89, 9.0, 0.6,\n",
    "                    0.08, -0.12, 0.12, 0.08,\n",
    "                    172, 172])\n",
    "parameter_names = ['sigma', 'length_a', 'scale', 'zero_shift',\n",
    "                   'resolution_u', 'resolution_v', 'resolution_w', 'resolution_y',\n",
    "                   'intensity', 'intensity-1']\n",
    "\n",
    "\n",
    "def generate_starting_theta():\n",
    "    \"\"\" Generate random initial starting point pretty close to theta_0 \"\"\"\n",
    "\n",
    "    # parameters defining how much randomness to add to theta_0\n",
    "    dx_sigma = 1\n",
    "    dx_lattice_parameter = 0.01\n",
    "    dx_scale = 0.1\n",
    "    dx_zeroshift = 0.03\n",
    "    dx_reso = 0.01\n",
    "    dx_bkg = 5\n",
    "\n",
    "    # randomize theta\n",
    "    theta = theta_0.copy()\n",
    "    theta[0] += np.random.uniform(-dx_sigma, dx_sigma)\n",
    "\n",
    "    for i in [1]:\n",
    "        theta[i] += np.random.uniform(-dx_lattice_parameter, dx_lattice_parameter)\n",
    "\n",
    "    theta[2] += np.random.uniform(-dx_scale, dx_scale)\n",
    "    theta[3] += np.random.uniform(-dx_zeroshift, dx_zeroshift)\n",
    "\n",
    "    theta[4] += np.random.uniform(-dx_reso, dx_reso)\n",
    "    theta[5] += np.random.uniform(-dx_reso, dx_reso)\n",
    "    theta[6] += np.random.uniform(-dx_reso, dx_reso)\n",
    "    theta[7] += np.random.uniform(-dx_reso, dx_reso)\n",
    "\n",
    "    theta[8] += np.random.uniform(-dx_bkg, dx_bkg)\n",
    "    theta[9] += np.random.uniform(-dx_bkg, dx_bkg)\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "def set_job_parameters(job, theta):\n",
    "    \"\"\"\n",
    "    Set all the parameters for the job.\n",
    "    theta[0] is sigma and is thus not used\n",
    "    \"\"\"\n",
    "\n",
    "    job.phases[0].cell.length_a = theta[1]\n",
    "    job.phases[0].scale = theta[2]\n",
    "    job.pattern.zero_shift = theta[3]\n",
    "    job.parameters.resolution_u = theta[4]\n",
    "    job.parameters.resolution_v = theta[5]\n",
    "    job.parameters.resolution_w = theta[6]\n",
    "    job.parameters.resolution_y = theta[7]\n",
    "    job.backgrounds[0][0].y = theta[8]\n",
    "    job.backgrounds[0][1].y = theta[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d0a4b",
   "metadata": {},
   "source": [
    "## Probability functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d542e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.506723Z",
     "start_time": "2024-11-11T21:04:53.504212Z"
    }
   },
   "outputs": [],
   "source": [
    "# define all probabilities, priors, likelihoods, posterios\n",
    "\n",
    "\n",
    "def log_gaussian_likelihood(theta):\n",
    "\n",
    "    # set parameters\n",
    "    sigma = theta[0]\n",
    "    set_job_parameters(job, theta)\n",
    "\n",
    "    # if calculation fails for any reason, return -inf\n",
    "    try:\n",
    "        y_predicted = job.calculate_profile()\n",
    "    except ArithmeticError:\n",
    "        return -np.inf\n",
    "\n",
    "    # if y contains nan then return -inf\n",
    "    if np.any(np.isnan(y_predicted)):\n",
    "        return -np.inf\n",
    "\n",
    "    # compute log-likelihood\n",
    "    sigmas = sigma * np.sqrt(meas_y)\n",
    "    LL = -0.5 * np.sum(np.log(2 * np.pi * sigmas ** 2) + (meas_y - y_predicted) ** 2 / sigmas ** 2)\n",
    "    return LL\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    sigma = theta[0]\n",
    "    if sigma < 0 or sigma > 1000:\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "\n",
    "def log_posterior(theta):\n",
    "    return log_prior(theta) + log_gaussian_likelihood(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e5887",
   "metadata": {},
   "source": [
    "## Load the data and setup Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b28ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.868365Z",
     "start_time": "2024-11-11T21:04:53.512300Z"
    }
   },
   "outputs": [],
   "source": [
    "# create job\n",
    "job = ed.Job()\n",
    "\n",
    "# load cif\n",
    "ed.download_from_repository('lbco_adp.cif', destination='data')\n",
    "cif_fname = 'data/lbco_adp.cif'\n",
    "job.add_phase_from_file(cif_fname)\n",
    "\n",
    "# load diffraction data\n",
    "ed.download_from_repository('hrpt.xye', destination='data')\n",
    "meas_fname = 'data/hrpt.xye'\n",
    "meas_x, meas_y, meas_e = np.loadtxt(meas_fname, unpack=True)\n",
    "print('Data shape:', meas_x.shape, meas_y.shape)\n",
    "job.add_experiment_from_file(meas_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff2ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:53.877347Z",
     "start_time": "2024-11-11T21:04:53.874043Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "job.parameters.wavelength = 1.494\n",
    "\n",
    "# add background\n",
    "job.set_background([(meas_x[0], 170),\n",
    "                    (meas_x[-1], 170)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2033f34",
   "metadata": {},
   "source": [
    "Note here that no parameters are set to be refined. The MCMC simulations will be carried out using `emcee` package which will use the `log_posterior` function to sample the posterior.\n",
    "The `job` will only be used to calculate the diffraction pattern for the parameters that `emcee` will sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe66a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:54.034948Z",
     "start_time": "2024-11-11T21:04:53.882614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check if theta_0 is reasonable\n",
    "set_job_parameters(job, theta_0)\n",
    "y_initial = job.calculate_profile()\n",
    "rmse_initial = compute_rmse(meas_y, y_initial)\n",
    "msew_initial = compute_mse_weighted(meas_y, y_initial)\n",
    "print(f'Initial: RMSE {rmse_initial:.3f}, MSE-weighted {msew_initial:.3f}')\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(11, 4.5))\n",
    "plt.plot(meas_x, meas_y, label='Exp')\n",
    "plt.plot(meas_x, y_initial, label='Initial')\n",
    "plt.plot(meas_x, meas_y - y_initial-500, label='Diff')\n",
    "plt.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7027fea",
   "metadata": {},
   "source": [
    "## Run MCMC sampling\n",
    "\n",
    "Next, we define the hyper-parameters to be used for the MCMC sampling\n",
    "\n",
    "The MCMC is carried out by multiple independent \"walkers\".\n",
    "\n",
    "* `n_steps` sets how many steps/iterations each walker will carry out\n",
    "* `n_walkers` sets how many walkers to use\n",
    "* `n_parameters` is the total number of parameters being optimized\n",
    "* `n_every` how often to record store the MCMC trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9a8a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:54.071807Z",
     "start_time": "2024-11-11T21:04:54.070092Z"
    }
   },
   "outputs": [],
   "source": [
    "# MCMC parameters\n",
    "n_walkers = 15            # number of MCMC walkers\n",
    "n_every = 1               # keep every x:th sample\n",
    "n_steps = 50 // n_every   # steps per walker\n",
    "n_parameters = 10         # number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b252d08",
   "metadata": {},
   "source": [
    "Next, we generate the starting parameters for all walkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de3b55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:04:55.558017Z",
     "start_time": "2024-11-11T21:04:54.091198Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate starting points for walkers\n",
    "theta_start = [theta_0.copy()]\n",
    "for _ in range(n_walkers-1):\n",
    "    theta_start.append(generate_starting_theta())\n",
    "theta_start = np.array(theta_start).copy()\n",
    "print('theta start shape:', theta_start.shape)\n",
    "\n",
    "# sanity check starting points such that there is no horribly starting points with e.g. NaNs\n",
    "for it, theta in enumerate(theta_start):\n",
    "    set_job_parameters(job, theta)\n",
    "    y = job.calculate_profile()\n",
    "    rmse = compute_rmse(meas_y, y)\n",
    "    msew = compute_mse_weighted(meas_y, y)\n",
    "    logp = log_posterior(theta)\n",
    "\n",
    "    print(f'Walker {it:2}: log-posterior {logp:11.5f} | RMSE {rmse:.3f} | MSE-weighted {msew:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f95d6",
   "metadata": {},
   "source": [
    "In order make emcee run with fewer walkers than twice the number of parameters, we need to set `sampler._moves[0].live_dangerously = True `, but this is often unadvisable.\n",
    "\n",
    "Due the starting points for the walkers being quite similar we also may need to set `skip_initial_state_check=True` in order to avoid poor conditioned starting point error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494cb4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:10.976931Z",
     "start_time": "2024-11-11T21:04:55.565286Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "sampler = emcee.EnsembleSampler(n_walkers, n_parameters, log_posterior)\n",
    "sampler._moves[0].live_dangerously = True\n",
    "sampler.run_mcmc(theta_start, n_steps, progress=True, thin_by=n_every, skip_initial_state_check=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d20eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:10.997965Z",
     "start_time": "2024-11-11T21:06:10.995933Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = sampler.chain\n",
    "logp = sampler.lnprobability\n",
    "steps = n_every * np.arange(0, samples.shape[1])\n",
    "print('samples shape:', samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16b26b",
   "metadata": {},
   "source": [
    "First we'll plot the posterior of all walkers to check convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49938c77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:11.219709Z",
     "start_time": "2024-11-11T21:06:11.022608Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 5))\n",
    "for walker_ind in range(n_walkers):\n",
    "    plt.plot(steps, logp[walker_ind, :], label=f'Walker {walker_ind}')\n",
    "plt.legend()\n",
    "plt.ylabel('Log posterior')\n",
    "plt.xlabel('MCMC iteration')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7f625",
   "metadata": {},
   "source": [
    "Next, we'll plot the MCMC trajectory of the parameters for a few walkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa75307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:11.743057Z",
     "start_time": "2024-11-11T21:06:11.268185Z"
    }
   },
   "outputs": [],
   "source": [
    "walkers_to_plot = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(11, 14))\n",
    "for i in range(n_parameters):\n",
    "    ax = axes.flat[i]\n",
    "    name = parameter_names[i]\n",
    "    for walker_ind in walkers_to_plot:\n",
    "        ax.plot(steps, samples[walker_ind, :, i], label=f'Walker {walker_ind}')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xlabel('MCMC iteration')\n",
    "    if i == 0:\n",
    "        ax.legend(loc=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfb9ca",
   "metadata": {},
   "source": [
    "Now we extract the optimal choice of parameters and their standard-deviation.    \n",
    "We throw away the equilibration period of the MCMC simulations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c18d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:11.755196Z",
     "start_time": "2024-11-11T21:06:11.753435Z"
    }
   },
   "outputs": [],
   "source": [
    "n_throw_away = 2000 // n_every  # number of equilibration steps to throw away\n",
    "samples_flat = samples[:, n_throw_away:, :].reshape(-1, n_parameters)\n",
    "print('samples shape: ', samples.shape)\n",
    "print('samples_flat shape:', samples_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe79438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:11.830539Z",
     "start_time": "2024-11-11T21:06:11.774804Z"
    }
   },
   "outputs": [],
   "source": [
    "# select best model\n",
    "ind = np.argmax(logp)\n",
    "hp_loc = np.unravel_index(ind, logp.shape)\n",
    "theta_best = samples[hp_loc]\n",
    "\n",
    "# calculate spectra with best model\n",
    "set_job_parameters(job, theta_best)\n",
    "y = job.calculate_profile()\n",
    "rmse_refined = compute_rmse(meas_y, y)\n",
    "msew_refined = compute_mse_weighted(meas_y, y)\n",
    "print(f'Best model: RMSE {rmse_refined:.3f}, MSE-weighted {msew_refined:.3f}, sigma {theta_best[0]:.3f}')\n",
    "\n",
    "# estimate errors of parameters\n",
    "stds = samples_flat.std(axis=0)\n",
    "\n",
    "# Save the data to be analyzed\n",
    "data = dict(names=parameter_names, steps=steps, samples=samples, logp=logp)\n",
    "parameter_dict = dict()\n",
    "for name, val, err in zip(parameter_names, theta_best, stds):\n",
    "    key = name\n",
    "    if name in parameter_dict:\n",
    "        key = key + '-1'\n",
    "    print(f'{key:15} {val:12.5f} , err {err:8.5f}')\n",
    "    parameter_dict[key] = val, err\n",
    "data['parameters'] = parameter_dict\n",
    "#np.save(f'Fitting-emcee_pd-neut-cwl_LBCO-HRPT_steps{n_steps}_walkers{n_walkers}.npy', data, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba987cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:11.980832Z",
     "start_time": "2024-11-11T21:06:11.893142Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot refined diffraction pattern\n",
    "fig = plt.figure(figsize=(11, 4.5))\n",
    "plt.plot(meas_x, meas_y, label='Exp')\n",
    "plt.plot(meas_x, y, label='Simulated')\n",
    "plt.plot(meas_x, meas_y - y-500, label='Diff')\n",
    "plt.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912dad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:06:12.222541Z",
     "start_time": "2024-11-11T21:06:12.002639Z"
    }
   },
   "outputs": [],
   "source": [
    "# corner plot\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "corner.corner(samples_flat, labels=parameter_names)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
